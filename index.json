[{"authors":["admin"],"categories":null,"content":"I am currently a graduate student at Machine Vision Lab of Harbin Institute of Technology. Before that, I received my B.Eng. degree from Harbin Engineering University in 2019. My research interests include computer vision and deep learning, focusing on object detection and instance segmentation. Recently, I started the remote research intern at MSC lab of UC Berkeley and my research topic is behavior prediction for autonomous driving.\n","date":1590969600,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1591747200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://xiaogangjia.github.io/author/xiaogang-jia/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xiaogang-jia/","section":"authors","summary":"I am currently a graduate student at Machine Vision Lab of Harbin Institute of Technology. Before that, I received my B.Eng. degree from Harbin Engineering University in 2019. My research interests include computer vision and deep learning, focusing on object detection and instance segmentation.","tags":null,"title":"Xiaogang Jia","type":"authors"},{"authors":["Xiaogang Jia"],"categories":[],"content":"Interaction Challenge in CVPR 2020 workshop, \u0026ldquo;Scalability in Autonomous Driving\u0026rdquo;  Workshop Leaderboard\nI ranked 5th in the regular track and ranked 1st for metric of MON.\nExperiments on Interaction and Argoverse  Report\nThe key method of Social-Gan, Pooling Module, computes relative positions between the ego one and all other people. However, this pattern may not work well in the motion prediction for autonomous driving, because for an ego vehicle, not all other vehicles contribute to its motion planning. In order to verify the influence of the Pooling Module, we have conducted several experiments on the Interaction dataset and Argoverse dataset. All the results have been reported in a file with the Report link.\nIdea Visualization   Latest: predict trajectories of surrounding cars given the future trajectories of ego vehicle (conditional information)   A new pooling module that defines an effective field of view for ego car   Combine the information of lanes in a bird-view pattern   ","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"3c955cab1baca27b0180652c528e9171","permalink":"https://xiaogangjia.github.io/post/sgan/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/post/sgan/","section":"post","summary":"behavior prediction in highly interactive driving scenarios","tags":[],"title":"INTERPRET trajectory prediction","type":"post"},{"authors":["Xiaogang Jia","xianqiang yang","huijun gao"],"categories":null,"content":" Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1590451200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590451200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://xiaogangjia.github.io/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"IECON2020 - Annual Conference of the IEEE Industrial Electronics Society","tags":["source themes"],"title":"A Modified CenterNet for Crack Detection of Sanitary Ceramics","type":"publication"},{"authors":["Xiaogang Jia"],"categories":[],"content":"VisDrone Challenge in ECCV 2020 workshop  Leaderboard\nI achieved an AP of 22.72% in the object detection challenge.\nDetails Here I proposed a point-based network to localize objects in a low-resolution feature map. To save computational costs, I used mobilenetv3 to be the backbone. Then K-Means is used as a post-processing method to generate high-quality clusters.\nBoth original images and cropped images are processed by the detector. The detector is based on CenterNet and Hourglass-104. The model is initialized with weights pre-trained on MS COCO and I trained it for 30 epochs. In the end, all the predicted bounding boxes are merged by standard NMS.\nTest on challenge set    AP     22.72%    Test on validation set    AP AP50 AP75     31.06% 54.69% 29.09%    ","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590969600,"objectID":"cafa8454aaa0a2b05db8ef07a99c9bec","permalink":"https://xiaogangjia.github.io/post/visdrone/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/post/visdrone/","section":"post","summary":"object detection in bird's eye view","tags":[],"title":"Object Detection in Aerial Images","type":"post"},{"authors":["zhihao zhang","xianqiang yang","Xiaogang Jia"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   ","date":1583020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583020800,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://xiaogangjia.github.io/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"The WSDIS measure for multi-scale template matching in the wild is proposed in this paper. For computational efficiency, this method is based on one-directional NN search on appearance from the candidate window to the template.","tags":["source themes"],"title":"Scale-Adaptive NN-based Similarity for Robust Template Matching","type":"publication"},{"authors":["Xiaogang Jia"],"categories":[],"content":"Overview of the detector Backbone This work is based on CenterNet. I simplified the original ResNet18 and the volume of the final model is 34.3MB. It also realized full-resolution prediction which is beneficial for point-based detection. Adaptive feature fusion I introduced an extra branch with shallow layers to strengthen the feature representation. Then an adaptive feature fusion method is used to fuse main features with low-level features. This module was realized by a 1*1 conv layer and a softmax function, so that the network was able to learn the weights between deep-layer features and shallow-layer features.\nExperiment on the validation set    AP50 Volume FPS     96.16% 34.3MB 30    ","date":1580860800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580515200,"objectID":"137ceaf848c2890cb8c20e0c99db875c","permalink":"https://xiaogangjia.github.io/post/defect/","publishdate":"2020-02-05T00:00:00Z","relpermalink":"/post/defect/","section":"post","summary":"a robust and real-time anchor-free model for defect detection","tags":[],"title":"Defect Detection for Sanitary Ceramics","type":"post"},{"authors":["Xiaogang Jia"],"categories":[],"content":"Tasks  Original YOLOv3 with official pre-trained weights is used to detect workers. YOLOv3 with modified anchors is used to detect smoke and fire. Mask-RCNN is used to segment the coal region in a pre-defined area. I also find that a simple U-Net can perform very well.  Demos P.S. For some reason, all models here are not reported with metrics.\n","date":1567123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"c4c29ebcf6d1ea0b1d4363e237e1fb1e","permalink":"https://xiaogangjia.github.io/post/yingyingying/","publishdate":"2019-08-30T00:00:00Z","relpermalink":"/post/yingyingying/","section":"post","summary":"detection for coal piling, smoke, fire and person","tags":[],"title":"Intelligent Monitoring System for Belt Conveyor","type":"post"},{"authors":["Xiaogang Jia"],"categories":[],"content":"Pipeline  Original YOLOv2 with VOC pre-trained weights is used to detect all cars in the image. A novel CNN is proposed to predict a set of affine transformation parameters which are used to extract the area of license plates. Then a perspective transformation is applied to rectify the distorted license plates. Simplify the backbone of YOLOv2 to detect characters in the rectified regions.  Experiment    Total TP Accuracy FPS     200 189 94.5% 10    Examples for dataset authentic LPs and synthesized LPs ","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"004e0c83bc471917ee4a76e922ed68e2","permalink":"https://xiaogangjia.github.io/post/lp/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/post/lp/","section":"post","summary":"an end-to-end deep learning system for LPs recognition","tags":[],"title":"License Plate Recognition in Natural Scenes","type":"post"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://xiaogangjia.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://xiaogangjia.github.io/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["deep learning"],"title":"Internal Project","type":"project"}]